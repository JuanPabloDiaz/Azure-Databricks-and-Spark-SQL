{
    "cells": [
     {
      "cell_type": "markdown",
      "id": "introduction",
      "metadata": {},
      "source": [
       "# Introduction to Databricks File System Utilities\n",
       "\n",
       "In this demo, we’ll explore the Databricks file system utilities. Databricks includes a built-in utility called **dbutils** that simplifies common tasks within notebooks.\n",
       "\n",
       "For now, we’re focusing solely on the file system operations. So, let’s click on **File System Utility** and see it in action!\n",
       "\n",
       "Databricks’ file system utilities provide a set of commands to manage files and directories in the Databricks File System (DBFS) and other supported storage systems. For example, you can:\n",
       "\n",
       "- Copy files from one directory to another\n",
       "- Return the contents of a file as a UTF-8 encoded string\n",
       "- List the contents of a directory\n",
       "- Remove a file or directory contents\n",
       "\n",
       "Let’s head over to Databricks and see why this is useful."
      ]
     },
     {
      "cell_type": "markdown",
      "id": "databricks-fs",
      "metadata": {},
      "source": [
       "## Databricks File System Overview\n",
       "\n",
       "Here is our Databricks File System under Catalog. We have the **FileSystem** directory and a **tables** subdirectory. Although you can view the contents via the UI, you can also list them using the Databricks file system utility."
      ]
     },
     {
      "cell_type": "markdown",
      "id": "list-root",
      "metadata": {},
      "source": [
       "### Listing the Root Path\n",
       "\n",
       "All you do is provide a path; I'll provide the root path:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "list-root-code",
      "metadata": {},
      "outputs": [],
      "source": [
       "# List the contents of the root directory in DBFS\n",
       "dbutils.fs.ls(\"/\")"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "explain-datasets",
      "metadata": {},
      "source": [
       "The output might not be super clear, but it appears that we have a **FileStore** directory as well as **databricks-datasets** and **databricks-results**.\n",
       "\n",
       "The last two directories are not visible in the DBFS browser. These are special system directories provided by Databricks:\n",
       "\n",
       "- **dbfs:/databricks-datasets/** is a read-only mount that offers a collection of sample datasets for learning and testing.\n",
       "- **dbfs:/databricks-results/** is used by Databricks to store outputs, logs, or results from jobs and interactive queries.\n",
       "\n",
       "Let's view the contents of the **databricks-datasets** directory:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "list-datasets",
      "metadata": {},
      "outputs": [],
      "source": [
       "# List the contents of the databricks-datasets directory\n",
       "dbutils.fs.ls(\"dbfs:/databricks-datasets/\")"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "display-datasets",
      "metadata": {},
      "source": [
       "For a nicer output, we can embed this in the `display` function:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "display-datasets-code",
      "metadata": {},
      "outputs": [],
      "source": [
       "# Display the contents of databricks-datasets with better formatting\n",
       "display(dbutils.fs.ls(\"dbfs:/databricks-datasets/\"))"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "head-readme",
      "metadata": {},
      "source": [
       "### Displaying File Contents with `head`\n",
       "\n",
       "Let's now use the `head` method to display one of the files. We'll display the README markdown file from the datasets:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "head-readme-code",
      "metadata": {},
      "outputs": [],
      "source": [
       "# Show the first few bytes of the README.md file\n",
       "dbutils.fs.head(\"dbfs:/databricks-datasets/README.md\")"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "copy-file",
      "metadata": {},
      "source": [
       "The raw data of the file is now displayed above.\n",
       "\n",
       "### Copying a File\n",
       "\n",
       "Now, let me show you how to copy a file from one location to another. We'll copy the README markdown file and store it in our **FileStore** directory.\n",
       "\n",
       "The `cp` method takes two arguments: the source path and the target path."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "copy-file-code",
      "metadata": {},
      "outputs": [],
      "source": [
       "# Copy the README.md file from databricks-datasets to FileStore\n",
       "dbutils.fs.cp(\"dbfs:/databricks-datasets/README.md\", \"dbfs:/FileStore/\")"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "check-filestore",
      "metadata": {},
      "source": [
       "Let's check the contents of the **FileStore** to confirm the copy:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "list-filestore",
      "metadata": {},
      "outputs": [],
      "source": [
       "# Display the contents of FileStore\n",
       "display(dbutils.fs.ls(\"dbfs:/FileStore/\"))"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "delete-file",
      "metadata": {},
      "source": [
       "We have indeed copied the file from **databricks-datasets** to **FileStore**.\n",
       "\n",
       "### Deleting a File\n",
       "\n",
       "To delete the file, we can use the `rm` method:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "delete-file-code",
      "metadata": {},
      "outputs": [],
      "source": [
       "# Remove the file from FileStore (adjust the path if needed)\n",
       "dbutils.fs.rm(\"dbfs:/FileStore/\")"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "copy-directory",
      "metadata": {},
      "source": [
       "### Copying an Entire Directory\n",
       "\n",
       "First, let's view the contents of the **databricks-datasets** directory again:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "list-datasets-again",
      "metadata": {},
      "outputs": [],
      "source": [
       "display(dbutils.fs.ls(\"dbfs:/databricks-datasets/\"))"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "copy-weather",
      "metadata": {},
      "source": [
       "Now, I'll copy the **weather** directory from **databricks-datasets** to a folder in **FileStore**."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "copy-weather-code",
      "metadata": {},
      "outputs": [],
      "source": [
       "# Copy the weather directory recursively\n",
       "dbutils.fs.cp(\"dbfs:/databricks-datasets/weather/\", \"dbfs:/FileStore/weather\", True)"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "check-weather",
      "metadata": {},
      "source": [
       "Let's verify the copied directory in **FileStore**:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "list-weather",
      "metadata": {},
      "outputs": [],
      "source": [
       "display(dbutils.fs.ls(\"dbfs:/FileStore/\"))"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "delete-directory",
      "metadata": {},
      "source": [
       "### Deleting a Directory\n",
       "\n",
       "To delete a folder that contains files, you need to use the recursive flag. Simply calling `dbutils.fs.rm(\"dbfs:/FileStore/weather\")` won't work unless you specify recursion.\n",
       "\n",
       "Let's try deleting without recursion first:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "delete-weather-no-recursive",
      "metadata": {},
      "outputs": [],
      "source": [
       "# This may not delete the folder if it contains files\n",
       "dbutils.fs.rm(\"dbfs:/FileStore/weather\")"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "delete-directory-recursive",
      "metadata": {},
      "source": [
       "Now, let's delete the directory recursively by setting the second argument to `True`:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "delete-weather-recursive",
      "metadata": {},
      "outputs": [],
      "source": [
       "# Delete the weather directory and its contents recursively\n",
       "dbutils.fs.rm(\"dbfs:/FileStore/weather\", True)"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "conclusion",
      "metadata": {},
      "source": [
       "## Conclusion\n",
       "\n",
       "That concludes our demo of the Databricks File System Utilities. These utilities allow you to manage and interact with files and directories in DBFS and mounted storage directly within your notebooks—letting you list, read, write, copy, move, and delete files without leaving the interactive environment."
      ]
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "name": "python",
      "version": "3.x"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 5
   }